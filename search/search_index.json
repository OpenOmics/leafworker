{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"leafworker \ud83d\udd2c An awesome snakemake pipeline to run leafcutter This is the home of the pipeline, leafworker. Its long-term goals: to make running leafcutter easier, more reproducible, and more scalable. Overview \u00b6 Welcome to leafworker's documentation! This guide is the main source of documentation for users that are getting started with the leafworker pipeline . This pipeline is a wrapper around the leafcutter 0 , a tool for the analysis of RNA-seq data to identify and quantify alternative splicing events. The pipeline is designed to be highly scalable, reproducible, and easy to use. If you use this pipeline, please do not forget to cite leafcutter . The ./leafworker pipeline is composed several inter-related sub commands to setup and run the pipeline across different systems. Each of the available sub commands perform different functions: leafworker run Run the leafworker pipeline with your input files. leafworker unlock Unlocks a previous runs output directory. leafworker install Download remote reference files locally. leafworker cache Cache remote software containers locally. leafworker is a pipeline to make running leafcutter easier, more reproducible, and more scalable. It relies on technologies like Singularity 1 to maintain the highest-level of reproducibility. The pipeline consists of a series of data processing and quality-control steps orchestrated by Snakemake 2 , a flexible and scalable workflow management system, to submit jobs to a cluster. The pipeline is compatible with data generated from Illumina short-read sequencing technologies. As input, it accepts a set of BAM files and can be run locally on a compute instance or on-premise using a cluster. A user can define the method or mode of execution. The pipeline can submit jobs to a cluster using a job scheduler like SLURM (more coming soon!). A hybrid approach ensures the pipeline is accessible to all users. Before getting started, we highly recommend reading through the usage section of each available sub command. For more information about issues or trouble-shooting a problem, please checkout our FAQ prior to opening an issue on Github . Contribute \u00b6 This site is a living document, created for and by members like you. leafworker is maintained by the members of NCBR and is improved by continous feedback! We encourage you to contribute new content and make improvements to existing content via pull request to our GitHub repository . Citation \u00b6 If you use this software, please cite it as below: BibTex APA @software{Kuhn_OpenOmics_leafworker_2025, author = {Kuhn, Skyler}, title = {OpenOmics/leafworker}, month = apr, year = 2025, publisher = {Zenodo}, version = {v0.1.0}, doi = {10.5281/zenodo.15170953}, url = {https://doi.org/10.5281/zenodo.15170953} } Kuhn, S. (2025). OpenOmics/leafworker: v0.1.0. Zenodo. https://doi.org/10.5281/zenodo.15170953 For more citation style options, please visit the pipeline's Zenodo page . References \u00b6 0. Li, Y. I., Knowles, D. A., Humphrey, J., Barbeira, A. N., Dickinson, S. P., Im, H. K., & Pritchard, J. K. (2018). Annotation-free quantification of RNA splicing using LeafCutter. Nature genetics, 50(1), 151\u2013158. https://doi.org/10.1038/s41588-017-0004-9 1. Kurtzer GM, Sochat V, Bauer MW (2017). Singularity: Scientific containers for mobility of compute. PLoS ONE 12(5): e0177459. 2. Koster, J. and S. Rahmann (2018). \"Snakemake-a scalable bioinformatics workflow engine.\" Bioinformatics 34(20): 3600.","title":"About"},{"location":"#overview","text":"Welcome to leafworker's documentation! This guide is the main source of documentation for users that are getting started with the leafworker pipeline . This pipeline is a wrapper around the leafcutter 0 , a tool for the analysis of RNA-seq data to identify and quantify alternative splicing events. The pipeline is designed to be highly scalable, reproducible, and easy to use. If you use this pipeline, please do not forget to cite leafcutter . The ./leafworker pipeline is composed several inter-related sub commands to setup and run the pipeline across different systems. Each of the available sub commands perform different functions: leafworker run Run the leafworker pipeline with your input files. leafworker unlock Unlocks a previous runs output directory. leafworker install Download remote reference files locally. leafworker cache Cache remote software containers locally. leafworker is a pipeline to make running leafcutter easier, more reproducible, and more scalable. It relies on technologies like Singularity 1 to maintain the highest-level of reproducibility. The pipeline consists of a series of data processing and quality-control steps orchestrated by Snakemake 2 , a flexible and scalable workflow management system, to submit jobs to a cluster. The pipeline is compatible with data generated from Illumina short-read sequencing technologies. As input, it accepts a set of BAM files and can be run locally on a compute instance or on-premise using a cluster. A user can define the method or mode of execution. The pipeline can submit jobs to a cluster using a job scheduler like SLURM (more coming soon!). A hybrid approach ensures the pipeline is accessible to all users. Before getting started, we highly recommend reading through the usage section of each available sub command. For more information about issues or trouble-shooting a problem, please checkout our FAQ prior to opening an issue on Github .","title":"Overview"},{"location":"#contribute","text":"This site is a living document, created for and by members like you. leafworker is maintained by the members of NCBR and is improved by continous feedback! We encourage you to contribute new content and make improvements to existing content via pull request to our GitHub repository .","title":"Contribute"},{"location":"#citation","text":"If you use this software, please cite it as below: BibTex APA @software{Kuhn_OpenOmics_leafworker_2025, author = {Kuhn, Skyler}, title = {OpenOmics/leafworker}, month = apr, year = 2025, publisher = {Zenodo}, version = {v0.1.0}, doi = {10.5281/zenodo.15170953}, url = {https://doi.org/10.5281/zenodo.15170953} } Kuhn, S. (2025). OpenOmics/leafworker: v0.1.0. Zenodo. https://doi.org/10.5281/zenodo.15170953 For more citation style options, please visit the pipeline's Zenodo page .","title":"Citation"},{"location":"#references","text":"0. Li, Y. I., Knowles, D. A., Humphrey, J., Barbeira, A. N., Dickinson, S. P., Im, H. K., & Pritchard, J. K. (2018). Annotation-free quantification of RNA splicing using LeafCutter. Nature genetics, 50(1), 151\u2013158. https://doi.org/10.1038/s41588-017-0004-9 1. Kurtzer GM, Sochat V, Bauer MW (2017). Singularity: Scientific containers for mobility of compute. PLoS ONE 12(5): e0177459. 2. Koster, J. and S. Rahmann (2018). \"Snakemake-a scalable bioinformatics workflow engine.\" Bioinformatics 34(20): 3600.","title":"References"},{"location":"license/","text":"MIT License \u00b6 Copyright \u00a9 2023 OpenOmics Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#mit-license","text":"Copyright \u00a9 2023 OpenOmics Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"faq/questions/","text":"Frequently Asked Questions \u00b6 This page is still under construction. If you need immediate help, please open an issue on Github!","title":"General Questions"},{"location":"faq/questions/#frequently-asked-questions","text":"This page is still under construction. If you need immediate help, please open an issue on Github!","title":"Frequently Asked Questions"},{"location":"usage/cache/","text":"leafworker cache \u00b6 1. About \u00b6 The leafworker executable is composed of several inter-related sub commands. Please see leafworker -h for all available options. This part of the documentation describes options and concepts for leafworker cache sub command in more detail. With minimal configuration, the cache sub command enables you to cache remote software containers from Dockerhub . Caching remote software containers allows the pipeline to run in an offline mode where no requests are made. The cache sub command can also be used to pull our pre-built software container onto a new cluster or target system. These containers are normally pulled onto the filesystem when the pipeline runs; however, due to network issues or DockerHub pull rate limits, it may make sense to pull the resources once so a shared cache can be created. It is worth noting that a singularity cache cannot normally be shared across users. Singularity strictly enforces that a cache is owned by the user. To get around this issue, the cache subcommand can be used to create local SIFs on the filesystem from images on DockerHub. The path of these locally cached SIFs can be passed to the run sub commands --sif-cache option. Caching software containers is fast and easy! In its most basic form, leafworker cache only has one required input . 2. Synopsis \u00b6 $ ./leafworker cache [--help] [--dry-run] \\ --sif-cache SIF_CACHE The synopsis for each command shows its parameters and their usage. Optional parameters are shown in square brackets. A user must provide a directory to cache remote Docker images via the --sif-cache argument. Once the cache has pipeline completed, the local sif cache can be passed to the --sif-cache option of the leafworker run subcomand. This enables the pipeline to run in an offline mode. Use you can always use the -h option for information on a specific command. 2.1 Required Arguments \u00b6 --sif-cache SIF_CACHE Path where a local cache of SIFs will be stored. type: path Any images defined in config/containers.json will be pulled into the local filesystem. The path provided to this option can be passed to the --sif-cache option of the leafworker run subcomand. This allows for running the build and run pipelines in an offline mode where no requests are made to external sources. This is useful for avoiding network issues or DockerHub pull rate limits. Please see leafworker run for more information. Example: --sif-cache /data/$USER/cache 2.2 Options \u00b6 Each of the following arguments are optional and do not need to be provided. -h, --help Display Help. type: boolean flag Shows command's synopsis, help message, and an example command Example: --help --dry-run Dry run the pipeline. type: boolean flag Only displays what software container will be cached locally. Does not execute anything! Example: --dry-run 3. Example \u00b6 # Step 0.) Grab an interactive node (do not run on head node) srun -N 1 -n 1 --time = 12 :00:00 -p interactive --mem = 8gb --cpus-per-task = 4 --pty bash module purge module load snakemake/7.22.0-ufanewz # Step 1.) Dry run to see what will be pulled ./leafworker cache \\ --sif-cache /data/ $USER /cache \\ --dry-run # Step 2.) Cache remote resources locally. # This command will NOT automatically submit # a job to the cluster. As so, we recommend # submitting this next command to the cluster # as a job. Download speeds will vary so it # is best to set the wall time a few hours. ./leafworker cache --sif-cache /data/ $USER /cache","title":"leafworker cache"},{"location":"usage/cache/#leafworker-cache","text":"","title":"leafworker cache"},{"location":"usage/cache/#1-about","text":"The leafworker executable is composed of several inter-related sub commands. Please see leafworker -h for all available options. This part of the documentation describes options and concepts for leafworker cache sub command in more detail. With minimal configuration, the cache sub command enables you to cache remote software containers from Dockerhub . Caching remote software containers allows the pipeline to run in an offline mode where no requests are made. The cache sub command can also be used to pull our pre-built software container onto a new cluster or target system. These containers are normally pulled onto the filesystem when the pipeline runs; however, due to network issues or DockerHub pull rate limits, it may make sense to pull the resources once so a shared cache can be created. It is worth noting that a singularity cache cannot normally be shared across users. Singularity strictly enforces that a cache is owned by the user. To get around this issue, the cache subcommand can be used to create local SIFs on the filesystem from images on DockerHub. The path of these locally cached SIFs can be passed to the run sub commands --sif-cache option. Caching software containers is fast and easy! In its most basic form, leafworker cache only has one required input .","title":"1. About"},{"location":"usage/cache/#2-synopsis","text":"$ ./leafworker cache [--help] [--dry-run] \\ --sif-cache SIF_CACHE The synopsis for each command shows its parameters and their usage. Optional parameters are shown in square brackets. A user must provide a directory to cache remote Docker images via the --sif-cache argument. Once the cache has pipeline completed, the local sif cache can be passed to the --sif-cache option of the leafworker run subcomand. This enables the pipeline to run in an offline mode. Use you can always use the -h option for information on a specific command.","title":"2. Synopsis"},{"location":"usage/cache/#21-required-arguments","text":"--sif-cache SIF_CACHE Path where a local cache of SIFs will be stored. type: path Any images defined in config/containers.json will be pulled into the local filesystem. The path provided to this option can be passed to the --sif-cache option of the leafworker run subcomand. This allows for running the build and run pipelines in an offline mode where no requests are made to external sources. This is useful for avoiding network issues or DockerHub pull rate limits. Please see leafworker run for more information. Example: --sif-cache /data/$USER/cache","title":"2.1 Required Arguments"},{"location":"usage/cache/#22-options","text":"Each of the following arguments are optional and do not need to be provided. -h, --help Display Help. type: boolean flag Shows command's synopsis, help message, and an example command Example: --help --dry-run Dry run the pipeline. type: boolean flag Only displays what software container will be cached locally. Does not execute anything! Example: --dry-run","title":"2.2 Options"},{"location":"usage/cache/#3-example","text":"# Step 0.) Grab an interactive node (do not run on head node) srun -N 1 -n 1 --time = 12 :00:00 -p interactive --mem = 8gb --cpus-per-task = 4 --pty bash module purge module load snakemake/7.22.0-ufanewz # Step 1.) Dry run to see what will be pulled ./leafworker cache \\ --sif-cache /data/ $USER /cache \\ --dry-run # Step 2.) Cache remote resources locally. # This command will NOT automatically submit # a job to the cluster. As so, we recommend # submitting this next command to the cluster # as a job. Download speeds will vary so it # is best to set the wall time a few hours. ./leafworker cache --sif-cache /data/ $USER /cache","title":"3. Example"},{"location":"usage/install/","text":"leafworker install \u00b6 Note This pipeline does not have any reference files that need to be downloaded prior to running. As so, everything on this page can be safely ignored! We have bundled all the reference files for the pipeline within our Github repository. All the reference files are located within the resources folder . 1. About \u00b6 The leafworker executable is composed of several inter-related sub commands. Please see leafworker -h for all available options. This part of the documentation describes options and concepts for leafworker install sub command in more detail. With minimal configuration, the install sub command enables you to download the pipeline's resource bundle locally. This is necessary when setting up the pipeline on a new target system or cluster. The pipeline uses a set of reference files to process the data. These reference files are required and need to be available on the local file system prior to execution. This command can be used to download any required reference files of the pipeline. Since most resource bundles are very large; we recommend using multiple threads for pulling reference files concurrently. The resource bundle can be very large so please ensure you have sufficent disk space prior to running this sub command. Please Note: The resource bundle requires about 2 GB of available disk space. If you are running the pipeline on the Biowulf cluster, you do NOT need to download the pipeline's resource bundle. It is already accessible to all HPC users. This sub command is for users running the pipeline outside of the Biowulf cluster. Downloading the resource bundle is fast and easy! In its most basic form, leafworker install only has one required input . 2. Synopsis \u00b6 $ leafworker install [--help] [--dry-run] \\ [--force] [--threads] \\ --ref-path REF_PATH The synopsis for each command shows its parameters and their usage. Optional parameters are shown in square brackets. A user must provide a output directory for the reference file download via the --ref-path argument. Once the download of the resource bundle has completed, a new child directory called leafworker will be created. This new directory will contain all of the pipeline's required reference files. The path to this new directory can be passed to the --resource-bundle option of the leafworker run subcomand. This allow users outside of Biowulf to run the pipeline. Use you can always use the -h option for information on a specific command. 2.1 Required Arguments \u00b6 --ref-path REF_PATH Path where the resource bundle will be downloaded. type: path Any resouces defined in the 'config/install.json' will be pulled onto the local filesystem. After the files have been downloaded, a new directory with the name leafworker will be created. It contains all the required reference files of the pipeline. The path to this new directory can be passed to the run sub command's --resource-bundle option. Please see the run sub command for more information. Example: --ref-path /data/$USER/refs 2.2 Options \u00b6 Each of the following arguments are optional and do not need to be provided. -h, --help Display Help. type: boolean flag Shows command's synopsis, help message, and an example command Example: --help --dry-run Dry run the pipeline. type: boolean flag Displays what remote resources would be pulled. Does not execute anything! Example: --dry-run --force Force downloads all files. type: boolean flag By default, any files that do not exist locally are pulled; however if a previous instance of an install did not exit gracefully, it may be necessary to forcefully re-download all the files. Example: --force --threads Number of threads to use for concurrent file downloads. type: int default: 2 Max number of threads to use for concurrent file downloads. Example: --threads 12 3. Example \u00b6 # Step 0.) Grab an interactive node, # do not run on head node! srun -N 1 -n 1 --time = 12 :00:00 -p interactive --mem = 24gb --cpus-per-task = 12 --pty bash module purge module load snakemake/7.22.0-ufanewz # Step 1.) Dry-run download of the resource bundle leafworker install --ref-path /data/ $USER /refs \\ --force \\ --dry-run \\ --threads 12 # Step 2.) Download the resource bundle, # This command will NOT automatically submit # a job to the cluster. As so, we recommend # submitting this next command to the cluster # as a job. Download speeds will vary so it # is best to set the wall time to 2 days. leafworker install --ref-path /data/ $USER /refs \\ --force \\ --threads 12 # Checkout the downloaded files cd /data/ $USER /refs tree leafworker # leafworker/ # \u251c\u2500\u2500 kronatax_1222 # \u2502 \u2514\u2500\u2500 taxonomy.tab # \u2514\u2500\u2500 NCBI # \u2514\u2500\u2500 viral_genomes_taxid.fa","title":"leafworker install"},{"location":"usage/install/#leafworker-install","text":"Note This pipeline does not have any reference files that need to be downloaded prior to running. As so, everything on this page can be safely ignored! We have bundled all the reference files for the pipeline within our Github repository. All the reference files are located within the resources folder .","title":"leafworker install"},{"location":"usage/install/#1-about","text":"The leafworker executable is composed of several inter-related sub commands. Please see leafworker -h for all available options. This part of the documentation describes options and concepts for leafworker install sub command in more detail. With minimal configuration, the install sub command enables you to download the pipeline's resource bundle locally. This is necessary when setting up the pipeline on a new target system or cluster. The pipeline uses a set of reference files to process the data. These reference files are required and need to be available on the local file system prior to execution. This command can be used to download any required reference files of the pipeline. Since most resource bundles are very large; we recommend using multiple threads for pulling reference files concurrently. The resource bundle can be very large so please ensure you have sufficent disk space prior to running this sub command. Please Note: The resource bundle requires about 2 GB of available disk space. If you are running the pipeline on the Biowulf cluster, you do NOT need to download the pipeline's resource bundle. It is already accessible to all HPC users. This sub command is for users running the pipeline outside of the Biowulf cluster. Downloading the resource bundle is fast and easy! In its most basic form, leafworker install only has one required input .","title":"1. About"},{"location":"usage/install/#2-synopsis","text":"$ leafworker install [--help] [--dry-run] \\ [--force] [--threads] \\ --ref-path REF_PATH The synopsis for each command shows its parameters and their usage. Optional parameters are shown in square brackets. A user must provide a output directory for the reference file download via the --ref-path argument. Once the download of the resource bundle has completed, a new child directory called leafworker will be created. This new directory will contain all of the pipeline's required reference files. The path to this new directory can be passed to the --resource-bundle option of the leafworker run subcomand. This allow users outside of Biowulf to run the pipeline. Use you can always use the -h option for information on a specific command.","title":"2. Synopsis"},{"location":"usage/install/#21-required-arguments","text":"--ref-path REF_PATH Path where the resource bundle will be downloaded. type: path Any resouces defined in the 'config/install.json' will be pulled onto the local filesystem. After the files have been downloaded, a new directory with the name leafworker will be created. It contains all the required reference files of the pipeline. The path to this new directory can be passed to the run sub command's --resource-bundle option. Please see the run sub command for more information. Example: --ref-path /data/$USER/refs","title":"2.1 Required Arguments"},{"location":"usage/install/#22-options","text":"Each of the following arguments are optional and do not need to be provided. -h, --help Display Help. type: boolean flag Shows command's synopsis, help message, and an example command Example: --help --dry-run Dry run the pipeline. type: boolean flag Displays what remote resources would be pulled. Does not execute anything! Example: --dry-run --force Force downloads all files. type: boolean flag By default, any files that do not exist locally are pulled; however if a previous instance of an install did not exit gracefully, it may be necessary to forcefully re-download all the files. Example: --force --threads Number of threads to use for concurrent file downloads. type: int default: 2 Max number of threads to use for concurrent file downloads. Example: --threads 12","title":"2.2 Options"},{"location":"usage/install/#3-example","text":"# Step 0.) Grab an interactive node, # do not run on head node! srun -N 1 -n 1 --time = 12 :00:00 -p interactive --mem = 24gb --cpus-per-task = 12 --pty bash module purge module load snakemake/7.22.0-ufanewz # Step 1.) Dry-run download of the resource bundle leafworker install --ref-path /data/ $USER /refs \\ --force \\ --dry-run \\ --threads 12 # Step 2.) Download the resource bundle, # This command will NOT automatically submit # a job to the cluster. As so, we recommend # submitting this next command to the cluster # as a job. Download speeds will vary so it # is best to set the wall time to 2 days. leafworker install --ref-path /data/ $USER /refs \\ --force \\ --threads 12 # Checkout the downloaded files cd /data/ $USER /refs tree leafworker # leafworker/ # \u251c\u2500\u2500 kronatax_1222 # \u2502 \u2514\u2500\u2500 taxonomy.tab # \u2514\u2500\u2500 NCBI # \u2514\u2500\u2500 viral_genomes_taxid.fa","title":"3. Example"},{"location":"usage/run/","text":"leafworker run \u00b6 1. About \u00b6 The leafworker executable is composed of several inter-related sub commands. Please see leafworker -h for all available options. This part of the documentation describes options and concepts for leafworker run sub command in more detail. With minimal configuration, the run sub command enables you to start running leafworker pipeline. Setting up the leafworker pipeline is fast and easy! In its most basic form, leafworker run only has three required inputs . 2. Synopsis \u00b6 $ leafworker run [--help] \\ [--dry-run] [--job-name JOB_NAME] [--mode {{slurm,local}}] \\ [--sif-cache SIF_CACHE] [--singularity-cache SINGULARITY_CACHE] \\ [--silent] [--threads THREADS] [--tmp-dir TMP_DIR] \\ [--batch-id BATCH_ID] [--quantify-transcripts QUANTIFY_TRANSCRIPTS] \\ [--groups GROUPS] [--contrasts CONTRASTS] \\ --input INPUT [INPUT ...] \\ --output OUTPUT \\ --gtf GTF The synopsis for each command shows its arguments and their usage. Optional arguments are shown in square brackets. A user must provide a list of BAM (globbing is supported) to analyze via --input argument, an output directory to store results via --output argument, and a GTF file to define the transcriptome via --gtf . Use you can always use the -h option for information on a specific command. 2.1 Required arguments \u00b6 Each of the following arguments are required. Failure to provide a required argument will result in a non-zero exit-code. --input INPUT [INPUT ...] Input BAM file(s). type: BAM file(s) Input BAM files to process. BAM files for one or more samples can be provided. Multiple input BAM files should be seperated by a space. Globbing for multiple file is also supported! This makes selecting BAM files easy. Example: --input .tests/*.bam --output OUTPUT Path to an output directory. type: path This location is where the pipeline will create all of its output files, also known as the pipeline's working directory. If the provided output directory does not exist, it will be created automatically. Example: --output /data/$USER/leafworker_out --gtf GTF Annotation file in GTF format. type: GTF file This annotation file is used by leafcutter to identify splice junctions within the transcriptome. The input annotation file can be compressed with gzip. Example: --gtf .tests/gencode.v19.annotation.gtf.gz 2.2 Analysis options \u00b6 Each of the following arguments are optional, and do not need to be provided. --batch-id BATCH_ID Unique identifer to associate with a batch of samples. type: string default: None This option can be provided to ensure that differential splicing output files are not over-written between runs of the pipeline after updating the group file with additional covariates or dropping samples. By default, project-level files in \"differential_splicing\" could get over-written between pipeline runs if this option is not provided. The output directory name for a given contrast will resolve to {group1}_vs_{group2} within the differential_splicing folder. As so, if the groups file is updated to remove samples or add additional covariates without updating the group names, it could over write the previous analyses output files. Any identifer provided to this option will be used to create a sub directory in the \"differential_splicing\" folder. This ensures project-level files (which are unique) will not get over written. With that being said, it is always a good idea to provide this option. A unique batch id should be provided between runs. This batch id should be composed of alphanumeric characters and it should not contain a white space or tab characters. Here is a list of valid or acceptable characters: aA-Zz , 0-9 , - , _ . Example: --batch-id 2025_04_08 --quantify-transcripts QUANTIFY_TRANSCRIPTS FASTA file of transcripts to quantify. type: FASTA file default: None If this file is provided, an extra set of steps will run to estimate transcript expression using Salmon. If this option is also provided with a groups and contrasts file, an additional set of steps will run identify isoform switches using IsoformSwitchAnalyzeR. The provided FASTA file should contain transcripts annotated in the GTF file. If your annotation is from GENCODE, you can download a matching transcriptomic FASTA file from the same page the annotation was downloaded. You can also generated a transcriptomic FASTA file using gffread from the cufflinks suite via the following command: gffread -w transcripts.fa -g genome.fa gencode.annotation.gtf.gz Please note: If you intend to generate your own transcript.fa file using the command above, please provide the genomic FASTA file that was used to create the input BAM files and the same annotation provided to the pipeline's gtf option (i.e. --gtf ). Example: --quantify-transcripts transcripts.fa --groups GROUPS Groups file containing sample metadata. type: TSV file This tab delimited file is used to pair each sample to a group. Group information is used to setup comparsions across different groups of samples to find differential splicing. This tab-delimited file consists of two columns containing the base name of each sample and the name of their group(s), where multiple groups seperated can be seperated by a comma. The header of this file needs to be Sample for the column containing the sample base names and Group for the column with the group names. The base name of a given sample can be determined by removing its file extension from the sample's bam file. For example: WT_S4.bam becomes WT_S4 in the groups file. A group can represent anything from a timepoint, an experimental condition, a treatment, or disease state, etc. Please note that groups are should be composed of alphanumeric characters, cannot startwith a number, and cannot contain any - characters. Groups can contain _ characters. In the groups file the 1 st & 2 nd columns are required , where the 1 st column must be called Sample and the 2 nd column must be called Group . Any additional columns after the Sample & Group columns are optional. Any extra columns will be used for controlling covariates. This could be batches, sex, age, etc. Please note that any numeric values will be modeled as continuous variables . As so, please ensure any categorical values start with a letter. To perform differential splicing analyses, a groups & contrast file must be provided. Here are the contents of example groups file: Sample Group Sex WT_S1 G1,G3 M WT_S2 G1,G3 F WT_S3 G1,G3 M WT_S4 G1,G3 F WT_S5 G1,G4 M WT_S6 G2,G4 F WT_S7 G2,G4 M WT_S8 G2,G4 F WT_S9 G2,G4 M WT_S10 G2,G4 F where: \u2022 Sample is the base name of each sample's input BAM file without .bam file extension. \u2022 Group represents each sample's group name(s). \u2022 Any additional columns are optional covariates. Only the Sample and Group columns are required. Example: --groups .tests/groups.tsv --contrasts CONTRASTS Contrasts file containing comparisons to make. type: TSV file This tab delimited file is used to setup comparisons within different groups of samples. Please see the --groups option above for more information about how to define groups within a set of samples. The contrasts file consists of two columns containing the names of each group to compare. Please note this file has no column names or header. The group names defined in this file must also exist in the groups file. To perform differential splicing analysis, a groups and contrast file must be provided together. Here are the Contents of example contrasts file: G2 G1 G4 G3 where: \u2022 Any groups listed in this file must exist in the --groups file. \u2022 2 nd column represents the baseline of the comparison, i.e G1 and G3 in the example above. Example: --contrasts .tests/contrasts.tsv 2.3 Orchestration options \u00b6 Each of the following arguments are optional, and do not need to be provided. --dry-run Dry run the pipeline. type: boolean flag Displays what steps in the pipeline remain or will be run. Does not execute anything! Example: --dry-run --silent Silence standard output. type: boolean flag Reduces the amount of information directed to standard output when submitting master job to the job scheduler. Only the job id of the master job is returned. Example: --silent --mode {slurm,local} Execution Method. type: string default: slurm Execution Method. Defines the mode or method of execution. Vaild mode options include: slurm or local. slurm The slurm execution method will submit jobs to the SLURM workload manager . It is recommended running leafworker in this mode as execution will be significantly faster in a distributed environment. This is the default mode of execution. local Local executions will run serially on compute instance. This is useful for testing, debugging, or when a users does not have access to a high performance computing environment. If this option is not provided, it will default to a local execution mode. Example: --mode slurm --job-name JOB_NAME Set the name of the pipeline's master job. type: string default: pl:leafworker When submitting the pipeline to a job scheduler, like SLURM, this option always you to set the name of the pipeline's master job. By default, the name of the pipeline's master job is set to \"pl:leafworker\". Example: --job-name pl_id-42 --singularity-cache SINGULARITY_CACHE Overrides the $SINGULARITY_CACHEDIR environment variable. type: path default: --output OUTPUT/.singularity Singularity will cache image layers pulled from remote registries. This ultimately speeds up the process of pull an image from DockerHub if an image layer already exists in the singularity cache directory. By default, the cache is set to the value provided to the --output argument. Please note that this cache cannot be shared across users. Singularity strictly enforces you own the cache directory and will return a non-zero exit code if you do not own the cache directory! See the --sif-cache option to create a shareable resource. Example: --singularity-cache /data/$USER/.singularity --sif-cache SIF_CACHE Path where a local cache of SIFs are stored. type: path Uses a local cache of SIFs on the filesystem. This SIF cache can be shared across users if permissions are set correctly. If a SIF does not exist in the SIF cache, the image will be pulled from Dockerhub and a warning message will be displayed. The leafworker cache subcommand can be used to create a local SIF cache. Please see leafworker cache for more information. This command is extremely useful for avoiding DockerHub pull rate limits. It also remove any potential errors that could occur due to network issues or DockerHub being temporarily unavailable. We recommend running leafworker with this option when ever possible. Example: --sif-cache /data/$USER/SIFs --threads THREADS Max number of threads for each process. type: int default: 2 Max number of threads for each process. This option is more applicable when running the pipeline with --mode local . It is recommended setting this vaule to the maximum number of CPUs available on the host machine. Example: --threads 12 --tmp-dir TMP_DIR Max number of threads for each process. type: path default: None Path on the file system for writing temporary output files. Ideally, this path should point to a dedicated location on the filesystem for writing tmp files. On many systems, this location is set to somewhere in /data/scratch . If you need to inject a variable into this string that should NOT be expanded, please quote this options value in single quotes. Example: --tmp-dir /data/scratch/$USER 2.4 Miscellaneous options \u00b6 Each of the following arguments are optional, and do not need to be provided. -h, --help Display Help. type: boolean flag Shows command's synopsis, help message, and an example command Example: --help 3. Example \u00b6 # Step 1.) Grab an interactive node, # do not run on head node! srun -N 1 -n 1 --time = 1 :00:00 --mem = 8gb --cpus-per-task = 2 --pty bash module purge module load snakemake/7.22.0-ufanewz # Step 2A.) Dry-run the pipeline ./leafworker run --input .tests/*.bam \\ --output /data/ $USER /output \\ --gtf .tests/gencode.v19.annotation.gtf.gz \\ --mode slurm \\ --dry-run # Step 2B.) Run the leafworker pipeline # The slurm mode will submit jobs to # the cluster. It is recommended running # the pipeline in this mode. ./leafworker run --input .tests/*.bam \\ --output /data/ $USER /output \\ --gtf .tests/gencode.v19.annotation.gtf.gz \\ --mode slurm","title":"leafworker run"},{"location":"usage/run/#leafworker-run","text":"","title":"leafworker run"},{"location":"usage/run/#1-about","text":"The leafworker executable is composed of several inter-related sub commands. Please see leafworker -h for all available options. This part of the documentation describes options and concepts for leafworker run sub command in more detail. With minimal configuration, the run sub command enables you to start running leafworker pipeline. Setting up the leafworker pipeline is fast and easy! In its most basic form, leafworker run only has three required inputs .","title":"1. About"},{"location":"usage/run/#2-synopsis","text":"$ leafworker run [--help] \\ [--dry-run] [--job-name JOB_NAME] [--mode {{slurm,local}}] \\ [--sif-cache SIF_CACHE] [--singularity-cache SINGULARITY_CACHE] \\ [--silent] [--threads THREADS] [--tmp-dir TMP_DIR] \\ [--batch-id BATCH_ID] [--quantify-transcripts QUANTIFY_TRANSCRIPTS] \\ [--groups GROUPS] [--contrasts CONTRASTS] \\ --input INPUT [INPUT ...] \\ --output OUTPUT \\ --gtf GTF The synopsis for each command shows its arguments and their usage. Optional arguments are shown in square brackets. A user must provide a list of BAM (globbing is supported) to analyze via --input argument, an output directory to store results via --output argument, and a GTF file to define the transcriptome via --gtf . Use you can always use the -h option for information on a specific command.","title":"2. Synopsis"},{"location":"usage/run/#21-required-arguments","text":"Each of the following arguments are required. Failure to provide a required argument will result in a non-zero exit-code. --input INPUT [INPUT ...] Input BAM file(s). type: BAM file(s) Input BAM files to process. BAM files for one or more samples can be provided. Multiple input BAM files should be seperated by a space. Globbing for multiple file is also supported! This makes selecting BAM files easy. Example: --input .tests/*.bam --output OUTPUT Path to an output directory. type: path This location is where the pipeline will create all of its output files, also known as the pipeline's working directory. If the provided output directory does not exist, it will be created automatically. Example: --output /data/$USER/leafworker_out --gtf GTF Annotation file in GTF format. type: GTF file This annotation file is used by leafcutter to identify splice junctions within the transcriptome. The input annotation file can be compressed with gzip. Example: --gtf .tests/gencode.v19.annotation.gtf.gz","title":"2.1 Required arguments"},{"location":"usage/run/#22-analysis-options","text":"Each of the following arguments are optional, and do not need to be provided. --batch-id BATCH_ID Unique identifer to associate with a batch of samples. type: string default: None This option can be provided to ensure that differential splicing output files are not over-written between runs of the pipeline after updating the group file with additional covariates or dropping samples. By default, project-level files in \"differential_splicing\" could get over-written between pipeline runs if this option is not provided. The output directory name for a given contrast will resolve to {group1}_vs_{group2} within the differential_splicing folder. As so, if the groups file is updated to remove samples or add additional covariates without updating the group names, it could over write the previous analyses output files. Any identifer provided to this option will be used to create a sub directory in the \"differential_splicing\" folder. This ensures project-level files (which are unique) will not get over written. With that being said, it is always a good idea to provide this option. A unique batch id should be provided between runs. This batch id should be composed of alphanumeric characters and it should not contain a white space or tab characters. Here is a list of valid or acceptable characters: aA-Zz , 0-9 , - , _ . Example: --batch-id 2025_04_08 --quantify-transcripts QUANTIFY_TRANSCRIPTS FASTA file of transcripts to quantify. type: FASTA file default: None If this file is provided, an extra set of steps will run to estimate transcript expression using Salmon. If this option is also provided with a groups and contrasts file, an additional set of steps will run identify isoform switches using IsoformSwitchAnalyzeR. The provided FASTA file should contain transcripts annotated in the GTF file. If your annotation is from GENCODE, you can download a matching transcriptomic FASTA file from the same page the annotation was downloaded. You can also generated a transcriptomic FASTA file using gffread from the cufflinks suite via the following command: gffread -w transcripts.fa -g genome.fa gencode.annotation.gtf.gz Please note: If you intend to generate your own transcript.fa file using the command above, please provide the genomic FASTA file that was used to create the input BAM files and the same annotation provided to the pipeline's gtf option (i.e. --gtf ). Example: --quantify-transcripts transcripts.fa --groups GROUPS Groups file containing sample metadata. type: TSV file This tab delimited file is used to pair each sample to a group. Group information is used to setup comparsions across different groups of samples to find differential splicing. This tab-delimited file consists of two columns containing the base name of each sample and the name of their group(s), where multiple groups seperated can be seperated by a comma. The header of this file needs to be Sample for the column containing the sample base names and Group for the column with the group names. The base name of a given sample can be determined by removing its file extension from the sample's bam file. For example: WT_S4.bam becomes WT_S4 in the groups file. A group can represent anything from a timepoint, an experimental condition, a treatment, or disease state, etc. Please note that groups are should be composed of alphanumeric characters, cannot startwith a number, and cannot contain any - characters. Groups can contain _ characters. In the groups file the 1 st & 2 nd columns are required , where the 1 st column must be called Sample and the 2 nd column must be called Group . Any additional columns after the Sample & Group columns are optional. Any extra columns will be used for controlling covariates. This could be batches, sex, age, etc. Please note that any numeric values will be modeled as continuous variables . As so, please ensure any categorical values start with a letter. To perform differential splicing analyses, a groups & contrast file must be provided. Here are the contents of example groups file: Sample Group Sex WT_S1 G1,G3 M WT_S2 G1,G3 F WT_S3 G1,G3 M WT_S4 G1,G3 F WT_S5 G1,G4 M WT_S6 G2,G4 F WT_S7 G2,G4 M WT_S8 G2,G4 F WT_S9 G2,G4 M WT_S10 G2,G4 F where: \u2022 Sample is the base name of each sample's input BAM file without .bam file extension. \u2022 Group represents each sample's group name(s). \u2022 Any additional columns are optional covariates. Only the Sample and Group columns are required. Example: --groups .tests/groups.tsv --contrasts CONTRASTS Contrasts file containing comparisons to make. type: TSV file This tab delimited file is used to setup comparisons within different groups of samples. Please see the --groups option above for more information about how to define groups within a set of samples. The contrasts file consists of two columns containing the names of each group to compare. Please note this file has no column names or header. The group names defined in this file must also exist in the groups file. To perform differential splicing analysis, a groups and contrast file must be provided together. Here are the Contents of example contrasts file: G2 G1 G4 G3 where: \u2022 Any groups listed in this file must exist in the --groups file. \u2022 2 nd column represents the baseline of the comparison, i.e G1 and G3 in the example above. Example: --contrasts .tests/contrasts.tsv","title":"2.2 Analysis options"},{"location":"usage/run/#23-orchestration-options","text":"Each of the following arguments are optional, and do not need to be provided. --dry-run Dry run the pipeline. type: boolean flag Displays what steps in the pipeline remain or will be run. Does not execute anything! Example: --dry-run --silent Silence standard output. type: boolean flag Reduces the amount of information directed to standard output when submitting master job to the job scheduler. Only the job id of the master job is returned. Example: --silent --mode {slurm,local} Execution Method. type: string default: slurm Execution Method. Defines the mode or method of execution. Vaild mode options include: slurm or local. slurm The slurm execution method will submit jobs to the SLURM workload manager . It is recommended running leafworker in this mode as execution will be significantly faster in a distributed environment. This is the default mode of execution. local Local executions will run serially on compute instance. This is useful for testing, debugging, or when a users does not have access to a high performance computing environment. If this option is not provided, it will default to a local execution mode. Example: --mode slurm --job-name JOB_NAME Set the name of the pipeline's master job. type: string default: pl:leafworker When submitting the pipeline to a job scheduler, like SLURM, this option always you to set the name of the pipeline's master job. By default, the name of the pipeline's master job is set to \"pl:leafworker\". Example: --job-name pl_id-42 --singularity-cache SINGULARITY_CACHE Overrides the $SINGULARITY_CACHEDIR environment variable. type: path default: --output OUTPUT/.singularity Singularity will cache image layers pulled from remote registries. This ultimately speeds up the process of pull an image from DockerHub if an image layer already exists in the singularity cache directory. By default, the cache is set to the value provided to the --output argument. Please note that this cache cannot be shared across users. Singularity strictly enforces you own the cache directory and will return a non-zero exit code if you do not own the cache directory! See the --sif-cache option to create a shareable resource. Example: --singularity-cache /data/$USER/.singularity --sif-cache SIF_CACHE Path where a local cache of SIFs are stored. type: path Uses a local cache of SIFs on the filesystem. This SIF cache can be shared across users if permissions are set correctly. If a SIF does not exist in the SIF cache, the image will be pulled from Dockerhub and a warning message will be displayed. The leafworker cache subcommand can be used to create a local SIF cache. Please see leafworker cache for more information. This command is extremely useful for avoiding DockerHub pull rate limits. It also remove any potential errors that could occur due to network issues or DockerHub being temporarily unavailable. We recommend running leafworker with this option when ever possible. Example: --sif-cache /data/$USER/SIFs --threads THREADS Max number of threads for each process. type: int default: 2 Max number of threads for each process. This option is more applicable when running the pipeline with --mode local . It is recommended setting this vaule to the maximum number of CPUs available on the host machine. Example: --threads 12 --tmp-dir TMP_DIR Max number of threads for each process. type: path default: None Path on the file system for writing temporary output files. Ideally, this path should point to a dedicated location on the filesystem for writing tmp files. On many systems, this location is set to somewhere in /data/scratch . If you need to inject a variable into this string that should NOT be expanded, please quote this options value in single quotes. Example: --tmp-dir /data/scratch/$USER","title":"2.3 Orchestration options"},{"location":"usage/run/#24-miscellaneous-options","text":"Each of the following arguments are optional, and do not need to be provided. -h, --help Display Help. type: boolean flag Shows command's synopsis, help message, and an example command Example: --help","title":"2.4 Miscellaneous options"},{"location":"usage/run/#3-example","text":"# Step 1.) Grab an interactive node, # do not run on head node! srun -N 1 -n 1 --time = 1 :00:00 --mem = 8gb --cpus-per-task = 2 --pty bash module purge module load snakemake/7.22.0-ufanewz # Step 2A.) Dry-run the pipeline ./leafworker run --input .tests/*.bam \\ --output /data/ $USER /output \\ --gtf .tests/gencode.v19.annotation.gtf.gz \\ --mode slurm \\ --dry-run # Step 2B.) Run the leafworker pipeline # The slurm mode will submit jobs to # the cluster. It is recommended running # the pipeline in this mode. ./leafworker run --input .tests/*.bam \\ --output /data/ $USER /output \\ --gtf .tests/gencode.v19.annotation.gtf.gz \\ --mode slurm","title":"3. Example"},{"location":"usage/unlock/","text":"leafworker unlock \u00b6 1. About \u00b6 The leafworker executable is composed of several inter-related sub commands. Please see leafworker -h for all available options. This part of the documentation describes options and concepts for leafworker unlock sub command in more detail. With minimal configuration, the unlock sub command enables you to unlock a pipeline output directory. If the pipeline fails ungracefully, it maybe required to unlock the working directory before proceeding again. Snakemake will inform a user when it maybe necessary to unlock a working directory with an error message stating: Error: Directory cannot be locked . Please verify that the pipeline is not running before running this command. If the pipeline is currently running, the workflow manager will report the working directory is locked. The is the default behavior of snakemake, and it is normal. Do NOT run this command if the pipeline is still running! Please kill the master job and it's child jobs prior to running this command. Unlocking leafworker pipeline output directory is fast and easy! In its most basic form, leafworker unlock only has one required input . 2. Synopsis \u00b6 $ ./leafworker unlock [-h] --output OUTPUT The synopsis for this command shows its parameters and their usage. Optional parameters are shown in square brackets. A user must provide an output directory to unlock via --output argument. After running the unlock sub command, you can resume the build or run pipeline from where it left off by re-running it. Use you can always use the -h option for information on a specific command. 2.1 Required Arguments \u00b6 --output OUTPUT Output directory to unlock. type: path Path to a previous run's output directory. This will remove a lock on the working directory. Please verify that the pipeline is not running before running this command. Example: --output /data/$USER/leafworker_out 2.2 Options \u00b6 Each of the following arguments are optional and do not need to be provided. -h, --help Display Help. type: boolean Shows command's synopsis, help message, and an example command Example: --help 3. Example \u00b6 # Step 0.) Grab an interactive node (do not run on head node) srun -N 1 -n 1 --time = 12 :00:00 -p interactive --mem = 8gb --cpus-per-task = 4 --pty bash module purge module load snakemake/7.22.0-ufanewz # Step 1.) Unlock a pipeline output directory leafworker unlock --output /data/ $USER /output","title":"leafworker unlock"},{"location":"usage/unlock/#leafworker-unlock","text":"","title":"leafworker unlock"},{"location":"usage/unlock/#1-about","text":"The leafworker executable is composed of several inter-related sub commands. Please see leafworker -h for all available options. This part of the documentation describes options and concepts for leafworker unlock sub command in more detail. With minimal configuration, the unlock sub command enables you to unlock a pipeline output directory. If the pipeline fails ungracefully, it maybe required to unlock the working directory before proceeding again. Snakemake will inform a user when it maybe necessary to unlock a working directory with an error message stating: Error: Directory cannot be locked . Please verify that the pipeline is not running before running this command. If the pipeline is currently running, the workflow manager will report the working directory is locked. The is the default behavior of snakemake, and it is normal. Do NOT run this command if the pipeline is still running! Please kill the master job and it's child jobs prior to running this command. Unlocking leafworker pipeline output directory is fast and easy! In its most basic form, leafworker unlock only has one required input .","title":"1. About"},{"location":"usage/unlock/#2-synopsis","text":"$ ./leafworker unlock [-h] --output OUTPUT The synopsis for this command shows its parameters and their usage. Optional parameters are shown in square brackets. A user must provide an output directory to unlock via --output argument. After running the unlock sub command, you can resume the build or run pipeline from where it left off by re-running it. Use you can always use the -h option for information on a specific command.","title":"2. Synopsis"},{"location":"usage/unlock/#21-required-arguments","text":"--output OUTPUT Output directory to unlock. type: path Path to a previous run's output directory. This will remove a lock on the working directory. Please verify that the pipeline is not running before running this command. Example: --output /data/$USER/leafworker_out","title":"2.1 Required Arguments"},{"location":"usage/unlock/#22-options","text":"Each of the following arguments are optional and do not need to be provided. -h, --help Display Help. type: boolean Shows command's synopsis, help message, and an example command Example: --help","title":"2.2 Options"},{"location":"usage/unlock/#3-example","text":"# Step 0.) Grab an interactive node (do not run on head node) srun -N 1 -n 1 --time = 12 :00:00 -p interactive --mem = 8gb --cpus-per-task = 4 --pty bash module purge module load snakemake/7.22.0-ufanewz # Step 1.) Unlock a pipeline output directory leafworker unlock --output /data/ $USER /output","title":"3. Example"}]}