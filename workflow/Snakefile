# Python standard library
from os.path import join
import os, json
# 3rd party imports from pypi
from snakemake.io import expand
# Local imports
from scripts.common import (
    allocated,
    provided, 
    str_bool
)


# Global workflow variables
configfile: 'config.json'                      # Generated from user input and config/*.json
bindpath = config['bindpaths']                 # Singularity paths to bind to the container
samples  = config['samples']                   # Base name of input samples
workpath = config['project']['workpath']       # Pipeline's output directory

# Read in resource information,
# containing information about 
# threads, mem, walltimes, etc.
# TODO: Add handler for when the
# mode is set to local.
with open(join(workpath, 'config', 'cluster.json')) as fh:
    cluster = json.load(fh)


# Final output files of the pipeline
rule all:
    input:
        # BAM to BED output file,
        # @imported from rules/leafcutter.smk
        # @output of rule leafcutter_bam2bed
        expand(join(workpath,"temp","{name}.bed"),name=samples),
        # BED to Junction output file,
        # @imported from rules/leafcutter.smk
        # @output of rule leafcutter_bed2junc
        expand(join(workpath,"junctions","{name}.junc"),name=samples),
        # Gathered junction file,
        # @imported from rules/leafcutter.smk
        # @output of rule leafcutter_gatherjuncs
        join(workpath, "temp", "junction_files.txt"),
        # Clustering output file,
        # @imported from rules/leafcutter.smk
        # @output of rule leafcutter_clusterjuncs
        join(workpath, "junctions", "leafcutter_perind.counts.gz"),


# Import rules 
include: join("rules", "leafcutter.smk")
include: join("rules", "common.smk")
include: join("rules", "hooks.smk")
